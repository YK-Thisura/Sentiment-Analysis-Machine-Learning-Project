{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b415863d-ebc6-4252-9996-64878ae28037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e47291a-ea2e-488d-81a9-065bc57065fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../artifacts/sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dca65ef-236c-4e34-ad7a-71c3d8cbfdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d9edc2-e52d-459b-ba3f-e6da64d693b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8ab991-c007-43cc-9b42-79ee6c580027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b1a614-8d5a-4354-a9f3-003076d27724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36aa2289-9996-43f0-b817-bab059ed3860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7c71cc-ab5a-4080-a0c7-30e819b1d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d5f8b9-cdc4-47cc-9e2e-b7fe90fc594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bcd8394-28f2-4b00-b459-69e63573d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert uppercase to lowercase\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c141a1e7-4673-4830-8603-23770c06b75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #pregnancy test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>finally a transparant silicon case ^^ thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>we love this! would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm wired i know i'm george i was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>what amazing service! apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #pregnancy test https://goo.gl/h1...\n",
       "1   2      0  finally a transparant silicon case ^^ thanks t...\n",
       "2   3      0  we love this! would you go? #talk #makememorie...\n",
       "3   4      0  i'm wired i know i'm george i was made that wa...\n",
       "4   5      1  what amazing service! apple won't even talk to..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a18c3e2-0b24-455f-a8fa-db4676aea83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Links\n",
    "\n",
    "data[\"tweet\"] = data['tweet'].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*','',x, flags=re.MULTILINE) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9934fa-4bea-44d4-858a-7dfbf0c34525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #fingerprint #pregnancy test  #android #apps #...\n",
       "1    finally a transparant silicon case ^^ thanks t...\n",
       "2    we love this! would you go? #talk #makememorie...\n",
       "3    i'm wired i know i'm george i was made that wa...\n",
       "4    what amazing service! apple won't even talk to...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6165da45-2c9e-47c7-b399-c6b4059e7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1461a93d-9e3d-4015-afee-d69bdc3c2f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4508d4c5-ce11-4714-82e7-f0e9d1b56c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text  # Move the return statement outside the loop\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(remove_punctuations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67017f4f-6b0d-4947-a779-eafe4cdb0fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnancy test  android apps beaut...\n",
       "1    finally a transparant silicon case  thanks to ...\n",
       "2    we love this would you go talk makememories un...\n",
       "3    im wired i know im george i was made that way ...\n",
       "4    what amazing service apple wont even talk to m...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e510fee-0142-485a-8903-705f8ce0f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Numbers\n",
    "data[\"tweet\"] = data['tweet'].str.replace('\\d+','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a35dc761-4ce1-491f-8956-15e0ba517903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7915    live out loud lol liveoutloud selfie smile son...\n",
       "7916    we would like to wish you an amazing day make ...\n",
       "7917    helping my lovely  year old neighbor with her ...\n",
       "7918    finally got my smart pocket wifi stay connecte...\n",
       "7919    apple barcelona apple store bcn barcelona trav...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afd0bfbb-c471-48ef-821d-87b5db74a544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords\n",
    "\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dfd7cf3-0a96-4757-b1ce-579ea7c57243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3925e84b-b1fc-4c90-aaa3-938eb750994e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ../static/model...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords', download_dir='../static/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b44f2382-ec7b-4c20-922f-2de5203a1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw = file.read().splitlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "570cb384-6ca0-4781-8064-98f4204b68cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f8c241e-6407-4430-86f7-20aa22db0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcfb9bb7-e3b9-4674-9c27-9c2035d8d0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnancy test android apps beauti...\n",
       "1    finally transparant silicon case thanks uncle ...\n",
       "2    love would go talk makememories unplug relax i...\n",
       "3    im wired know im george made way iphone cute d...\n",
       "4    amazing service apple wont even talk question ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23290248-431d-4abb-8b74-f85cfd9c5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca3615b2-0b43-4578-99a3-540dc5445ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \" .join(ps.stem(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22433b51-3671-49ed-a331-e497c5809e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnanc test android app beauti c...\n",
       "1    final transpar silicon case thank uncl yay son...\n",
       "2    love would go talk makememori unplug relax iph...\n",
       "3    im wire know im georg made way iphon cute dave...\n",
       "4    amaz servic appl wont even talk question unles...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aadea712-5eaa-4f10-9652-34758dcca3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnanc test android app beauti c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>final transpar silicon case thank uncl yay son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>love would go talk makememori unplug relax iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wire know im georg made way iphon cute dave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>amaz servic appl wont even talk question unles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>live loud lol liveoutloud selfi smile soni mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>would like wish amaz day make everi minut coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>help love year old neighbor ipad morn made rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>final got smart pocket wifi stay connect anyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>appl barcelona appl store bcn barcelona travel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  fingerprint pregnanc test android app beauti c...\n",
       "1        2      0  final transpar silicon case thank uncl yay son...\n",
       "2        3      0  love would go talk makememori unplug relax iph...\n",
       "3        4      0  im wire know im georg made way iphon cute dave...\n",
       "4        5      1  amaz servic appl wont even talk question unles...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  live loud lol liveoutloud selfi smile soni mus...\n",
       "7916  7917      0  would like wish amaz day make everi minut coun...\n",
       "7917  7918      0  help love year old neighbor ipad morn made rea...\n",
       "7918  7919      0  final got smart pocket wifi stay connect anyti...\n",
       "7919  7920      0  appl barcelona appl store bcn barcelona travel...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a2d434c-db41-47cd-9ae5-080a73377d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buliding Vocabulary\n",
    "\n",
    "from collections import Counter\n",
    "vocab = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c11efd0d-a1bc-40fd-8287-7c9097ab2cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a849fa49-cb98-455c-9169-38bee632dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in data['tweet']:\n",
    "    vocab.update(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2384a2d1-83e5-4268-b206-755b7406f058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15949"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb384fe2-e8ad-43d6-888c-8ea0586aefdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9648c285-9e1e-417e-b5e2-dbb99466660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [key for key in vocab if vocab[key] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7396fc5-f46b-47bb-8a8f-44e6bb09babd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f984a1ce-5298-4674-a08b-44060be24985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocabulary(lines,filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w', encoding=\"utf-8\")\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "save_vocabulary(tokens,'../static/model/vocabulary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97cfc824-a65c-419b-8b31-619669f350d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data set to Train and Test\n",
    "\n",
    "x = data['tweet']\n",
    "y = data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bef7628f-155d-4613-aebd-729a143b7e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40836d41-d968-4f3c-8c2d-fcd9108c0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a76c545d-fa60-431b-b379-d39a93f4a6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6336,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cefe099-df1d-4b9a-90d1-20b13a68d3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4151ed4-9c3c-4574-89ad-d8aef797dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(ds, vocabulary):\n",
    "    vectorized_list = []\n",
    "\n",
    "    for sentence in ds:\n",
    "        # Initialize a zero vector with the same length as the vocabulary\n",
    "        sentence_list = np.zeros(len(vocabulary))\n",
    "\n",
    "        for i in range(len(vocabulary)):\n",
    "            # Check if the vocabulary word is in the sentence\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_list[i] = 1\n",
    "\n",
    "        # Append the vector to the list\n",
    "        vectorized_list.append(sentence_list)\n",
    "\n",
    "    # Convert the list of vectors into a NumPy array\n",
    "    vectorized_list_new = np.asarray(vectorized_list, dtype=np.float32)\n",
    "\n",
    "    return vectorized_list_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2936dd5f-b8cf-4a40-93e4-42c1ea8dca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_train = vectorizer(x_train, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "505d1db7-1e33-4c6a-b8ce-4fdb380342f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10838d14-4e39-47ba-834d-4d630aa1aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_test = vectorizer(x_test, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24c9a47d-86fb-4d96-abac-e358c7d8610e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f90d404-d969-4217-bb41-6282d75eb14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4732\n",
       "1    1604\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6674292-e5da-4732-a6a9-72eaddd10ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced.learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced.learn\n",
      "Successfully installed imbalanced.learn-0.12.4\n"
     ]
    }
   ],
   "source": [
    "# Handle Imbalance Dataset\n",
    "\n",
    "!pip install imbalanced.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0472884-0216-4a70-afb0-62cb6ac5f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9464, 1145) (9464,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "vectorized_x_train_smote, y_train_smote = smote.fit_resample(vectorized_x_train, y_train)\n",
    "print(vectorized_x_train_smote.shape, y_train_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f27c5e96-cbfc-49e7-bce6-83a847ca3c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4732\n",
       "1    4732\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5180fe7f-fb11-49af-911c-05cdcb16b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf1311dd-25e3-4a76-8b45-63a00e199a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def training_scores(y_act, y_pred):\n",
    "    acc = round(accuracy_score(y_act, y_pred), 3)\n",
    "    pr = round(precision_score(y_act, y_pred), 3)\n",
    "    rec = round(recall_score(y_act, y_pred), 3)\n",
    "    f1 = round(f1_score(y_act, y_pred), 3)\n",
    "    print(f'Training Scores:\\n\\tAccuracy = {acc}\\n\\tPrecision = {pr}\\n\\tRecall = {rec}\\n\\tF1-Score = {f1}')\n",
    "\n",
    "def validation_scores(y_act, y_pred):\n",
    "    acc = round(accuracy_score(y_act, y_pred), 3)\n",
    "    pr = round(precision_score(y_act, y_pred), 3)\n",
    "    rec = round(recall_score(y_act, y_pred), 3)\n",
    "    f1 = round(f1_score(y_act, y_pred), 3)\n",
    "    print(f'Training Scores:\\n\\tAccuracy = {acc}\\n\\tPrecision = {pr}\\n\\tRecall = {rec}\\n\\tF1-Score = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "11afa1f3-a0a4-4809-881f-54bb4120204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.938\n",
      "\tPrecision = 0.912\n",
      "\tRecall = 0.969\n",
      "\tF1-Score = 0.94\n",
      "Training Scores:\n",
      "\tAccuracy = 0.87\n",
      "\tPrecision = 0.712\n",
      "\tRecall = 0.86\n",
      "\tF1-Score = 0.779\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = lr.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = lr.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dedf4715-3dc4-43fa-8a4a-9a2e7f425756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.909\n",
      "\tPrecision = 0.868\n",
      "\tRecall = 0.964\n",
      "\tF1-Score = 0.914\n",
      "Training Scores:\n",
      "\tAccuracy = 0.879\n",
      "\tPrecision = 0.705\n",
      "\tRecall = 0.938\n",
      "\tF1-Score = 0.805\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = mnb.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = mnb.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c40382d-6f97-4c33-8482-a94110ba364d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 1.0\n",
      "\tPrecision = 1.0\n",
      "\tRecall = 1.0\n",
      "\tF1-Score = 1.0\n",
      "Training Scores:\n",
      "\tAccuracy = 0.81\n",
      "\tPrecision = 0.648\n",
      "\tRecall = 0.628\n",
      "\tF1-Score = 0.638\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = dt.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = dt.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef2a8c35-dde4-4d89-9a83-78a776dacc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 1.0\n",
      "\tPrecision = 1.0\n",
      "\tRecall = 1.0\n",
      "\tF1-Score = 1.0\n",
      "Training Scores:\n",
      "\tAccuracy = 0.868\n",
      "\tPrecision = 0.767\n",
      "\tRecall = 0.725\n",
      "\tF1-Score = 0.745\n"
     ]
    }
   ],
   "source": [
    "# Randome Forest\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = rf.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = rf.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d5f3d9e-99ee-45f4-94d6-a3839c917719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.979\n",
      "\tPrecision = 0.964\n",
      "\tRecall = 0.996\n",
      "\tF1-Score = 0.98\n",
      "Training Scores:\n",
      "\tAccuracy = 0.875\n",
      "\tPrecision = 0.75\n",
      "\tRecall = 0.796\n",
      "\tF1-Score = 0.772\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "svm.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = svm.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = svm.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "102fc68d-eb54-4272-b548-d8c005099ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../static/model/model.pickle', 'wb') as file:\n",
    "    pickle.dump(lr, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
