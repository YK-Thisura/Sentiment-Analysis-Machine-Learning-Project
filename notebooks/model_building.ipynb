{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b415863d-ebc6-4252-9996-64878ae28037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e47291a-ea2e-488d-81a9-065bc57065fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../artifacts/sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dca65ef-236c-4e34-ad7a-71c3d8cbfdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d9edc2-e52d-459b-ba3f-e6da64d693b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8ab991-c007-43cc-9b42-79ee6c580027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b1a614-8d5a-4354-a9f3-003076d27724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36aa2289-9996-43f0-b817-bab059ed3860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7c71cc-ab5a-4080-a0c7-30e819b1d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d5f8b9-cdc4-47cc-9e2e-b7fe90fc594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bcd8394-28f2-4b00-b459-69e63573d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert uppercase to lowercase\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c141a1e7-4673-4830-8603-23770c06b75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #pregnancy test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>finally a transparant silicon case ^^ thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>we love this! would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm wired i know i'm george i was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>what amazing service! apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #pregnancy test https://goo.gl/h1...\n",
       "1   2      0  finally a transparant silicon case ^^ thanks t...\n",
       "2   3      0  we love this! would you go? #talk #makememorie...\n",
       "3   4      0  i'm wired i know i'm george i was made that wa...\n",
       "4   5      1  what amazing service! apple won't even talk to..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a18c3e2-0b24-455f-a8fa-db4676aea83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Links\n",
    "\n",
    "data[\"tweet\"] = data['tweet'].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*','',x, flags=re.MULTILINE) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a9934fa-4bea-44d4-858a-7dfbf0c34525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #fingerprint #pregnancy test  #android #apps #...\n",
       "1    finally a transparant silicon case ^^ thanks t...\n",
       "2    we love this! would you go? #talk #makememorie...\n",
       "3    i'm wired i know i'm george i was made that wa...\n",
       "4    what amazing service! apple won't even talk to...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6165da45-2c9e-47c7-b399-c6b4059e7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1461a93d-9e3d-4015-afee-d69bdc3c2f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4508d4c5-ce11-4714-82e7-f0e9d1b56c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text  # Move the return statement outside the loop\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(remove_punctuations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67017f4f-6b0d-4947-a779-eafe4cdb0fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnancy test  android apps beaut...\n",
       "1    finally a transparant silicon case  thanks to ...\n",
       "2    we love this would you go talk makememories un...\n",
       "3    im wired i know im george i was made that way ...\n",
       "4    what amazing service apple wont even talk to m...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e510fee-0142-485a-8903-705f8ce0f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Numbers\n",
    "data[\"tweet\"] = data['tweet'].str.replace('\\d+','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a35dc761-4ce1-491f-8956-15e0ba517903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7915    live out loud lol liveoutloud selfie smile son...\n",
       "7916    we would like to wish you an amazing day make ...\n",
       "7917    helping my lovely  year old neighbor with her ...\n",
       "7918    finally got my smart pocket wifi stay connecte...\n",
       "7919    apple barcelona apple store bcn barcelona trav...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afd0bfbb-c471-48ef-821d-87b5db74a544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords\n",
    "\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dfd7cf3-0a96-4757-b1ce-579ea7c57243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3925e84b-b1fc-4c90-aaa3-938eb750994e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ../static/model...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords', download_dir='../static/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b44f2382-ec7b-4c20-922f-2de5203a1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw = file.read().splitlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "570cb384-6ca0-4781-8064-98f4204b68cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f8c241e-6407-4430-86f7-20aa22db0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcfb9bb7-e3b9-4674-9c27-9c2035d8d0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnancy test android apps beauti...\n",
       "1    finally transparant silicon case thanks uncle ...\n",
       "2    love would go talk makememories unplug relax i...\n",
       "3    im wired know im george made way iphone cute d...\n",
       "4    amazing service apple wont even talk question ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23290248-431d-4abb-8b74-f85cfd9c5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca3615b2-0b43-4578-99a3-540dc5445ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \" .join(ps.stem(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22433b51-3671-49ed-a331-e497c5809e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnanc test android app beauti c...\n",
       "1    final transpar silicon case thank uncl yay son...\n",
       "2    love would go talk makememori unplug relax iph...\n",
       "3    im wire know im georg made way iphon cute dave...\n",
       "4    amaz servic appl wont even talk question unles...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aadea712-5eaa-4f10-9652-34758dcca3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnanc test android app beauti c...</td>\n",
       "      <td>fingerprint pregnancy test  android apps beaut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>final transpar silicon case thank uncl yay son...</td>\n",
       "      <td>finally a transparant silicon case  thanks to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>love would go talk makememori unplug relax iph...</td>\n",
       "      <td>we love this would you go talk makememories un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wire know im georg made way iphon cute dave...</td>\n",
       "      <td>im wired i know im george i was made that way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>amaz servic appl wont even talk question unles...</td>\n",
       "      <td>what amazing service apple wont even talk to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>live loud lol liveoutloud selfi smile soni mus...</td>\n",
       "      <td>live out loud lol liveoutloud selfie smile son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>would like wish amaz day make everi minut coun...</td>\n",
       "      <td>we would like to wish you an amazing day make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>help love year old neighbor ipad morn made rea...</td>\n",
       "      <td>helping my lovely 90 year old neighbor with he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>final got smart pocket wifi stay connect anyti...</td>\n",
       "      <td>finally got my smart pocket wifi stay connecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>appl barcelona appl store bcn barcelona travel...</td>\n",
       "      <td>apple barcelona apple store bcn barcelona trav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet  \\\n",
       "0        1      0  fingerprint pregnanc test android app beauti c...   \n",
       "1        2      0  final transpar silicon case thank uncl yay son...   \n",
       "2        3      0  love would go talk makememori unplug relax iph...   \n",
       "3        4      0  im wire know im georg made way iphon cute dave...   \n",
       "4        5      1  amaz servic appl wont even talk question unles...   \n",
       "...    ...    ...                                                ...   \n",
       "7915  7916      0  live loud lol liveoutloud selfi smile soni mus...   \n",
       "7916  7917      0  would like wish amaz day make everi minut coun...   \n",
       "7917  7918      0  help love year old neighbor ipad morn made rea...   \n",
       "7918  7919      0  final got smart pocket wifi stay connect anyti...   \n",
       "7919  7920      0  appl barcelona appl store bcn barcelona travel...   \n",
       "\n",
       "                                          cleaned_tweet  \n",
       "0     fingerprint pregnancy test  android apps beaut...  \n",
       "1     finally a transparant silicon case  thanks to ...  \n",
       "2     we love this would you go talk makememories un...  \n",
       "3     im wired i know im george i was made that way ...  \n",
       "4     what amazing service apple wont even talk to m...  \n",
       "...                                                 ...  \n",
       "7915  live out loud lol liveoutloud selfie smile son...  \n",
       "7916  we would like to wish you an amazing day make ...  \n",
       "7917  helping my lovely 90 year old neighbor with he...  \n",
       "7918  finally got my smart pocket wifi stay connecte...  \n",
       "7919  apple barcelona apple store bcn barcelona trav...  \n",
       "\n",
       "[7920 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a2d434c-db41-47cd-9ae5-080a73377d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buliding Vocabulary\n",
    "\n",
    "from collections import Counter\n",
    "vocab = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c11efd0d-a1bc-40fd-8287-7c9097ab2cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a849fa49-cb98-455c-9169-38bee632dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in data['tweet']:\n",
    "    vocab.update(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2384a2d1-83e5-4268-b206-755b7406f058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15949"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb384fe2-e8ad-43d6-888c-8ea0586aefdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9648c285-9e1e-417e-b5e2-dbb99466660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [key for key in vocab if vocab[key] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7396fc5-f46b-47bb-8a8f-44e6bb09babd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f984a1ce-5298-4674-a08b-44060be24985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocabulary(lines,filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w', encoding=\"utf-8\")\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "save_vocabulary(tokens,'../static/model/vocabulary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97cfc824-a65c-419b-8b31-619669f350d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data set to Train and Test\n",
    "\n",
    "x = data['tweet']\n",
    "y = data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bef7628f-155d-4613-aebd-729a143b7e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.0 MB 2.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.1/11.0 MB 2.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.4/11.0 MB 3.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.2/11.0 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.0/11.0 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.5/11.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.0 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.3/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.9/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/44.8 MB 1.9 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 1.3/44.8 MB 3.2 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 2.1/44.8 MB 3.6 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 3.1/44.8 MB 3.8 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.4/44.8 MB 3.7 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.9/44.8 MB 3.0 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 4.7/44.8 MB 3.1 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 5.0/44.8 MB 3.1 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 5.2/44.8 MB 3.0 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 6.0/44.8 MB 2.9 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 6.3/44.8 MB 2.8 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 6.8/44.8 MB 2.7 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 7.6/44.8 MB 2.8 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 8.1/44.8 MB 2.7 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 8.7/44.8 MB 2.7 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 9.4/44.8 MB 2.8 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 9.7/44.8 MB 2.7 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 10.5/44.8 MB 2.8 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 11.3/44.8 MB 2.8 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 11.8/44.8 MB 2.8 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 12.6/44.8 MB 2.8 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 12.8/44.8 MB 2.7 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 13.6/44.8 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 13.9/44.8 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 14.9/44.8 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 15.5/44.8 MB 2.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 16.0/44.8 MB 2.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 16.8/44.8 MB 2.8 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 17.3/44.8 MB 2.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 18.1/44.8 MB 2.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 18.1/44.8 MB 2.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 18.4/44.8 MB 2.7 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 19.1/44.8 MB 2.7 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 19.4/44.8 MB 2.7 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 20.2/44.8 MB 2.7 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 20.4/44.8 MB 2.7 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 21.2/44.8 MB 2.7 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 21.8/44.8 MB 2.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 22.5/44.8 MB 2.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 23.1/44.8 MB 2.7 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 23.9/44.8 MB 2.7 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 24.1/44.8 MB 2.7 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 24.9/44.8 MB 2.7 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 26.0/44.8 MB 2.8 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 26.2/44.8 MB 2.7 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 27.3/44.8 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 27.5/44.8 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 28.0/44.8 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 28.8/44.8 MB 2.8 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 29.6/44.8 MB 2.8 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 30.1/44.8 MB 2.8 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 30.9/44.8 MB 2.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 31.5/44.8 MB 2.8 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 32.5/44.8 MB 2.8 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 33.0/44.8 MB 2.8 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 33.8/44.8 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 34.9/44.8 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 35.4/44.8 MB 2.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 36.2/44.8 MB 2.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 37.0/44.8 MB 2.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 38.0/44.8 MB 2.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 38.5/44.8 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 39.3/44.8 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 40.4/44.8 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 41.2/44.8 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.2/44.8 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.3/44.8 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.8 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40836d41-d968-4f3c-8c2d-fcd9108c0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a76c545d-fa60-431b-b379-d39a93f4a6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6336,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cefe099-df1d-4b9a-90d1-20b13a68d3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4151ed4-9c3c-4574-89ad-d8aef797dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(ds, vocabulary):\n",
    "    vectorized_list = []\n",
    "\n",
    "    for sentence in ds:\n",
    "        # Initialize a zero vector with the same length as the vocabulary\n",
    "        sentence_list = np.zeros(len(vocabulary))\n",
    "\n",
    "        for i in range(len(vocabulary)):\n",
    "            # Check if the vocabulary word is in the sentence\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_list[i] = 1\n",
    "\n",
    "        # Append the vector to the list\n",
    "        vectorized_list.append(sentence_list)\n",
    "\n",
    "    # Convert the list of vectors into a NumPy array\n",
    "    vectorized_list_new = np.asarray(vectorized_list, dtype=np.float32)\n",
    "\n",
    "    return vectorized_list_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2936dd5f-b8cf-4a40-93e4-42c1ea8dca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_train = vectorizer(x_train, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "505d1db7-1e33-4c6a-b8ce-4fdb380342f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10838d14-4e39-47ba-834d-4d630aa1aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_test = vectorizer(x_test, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24c9a47d-86fb-4d96-abac-e358c7d8610e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f90d404-d969-4217-bb41-6282d75eb14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4713\n",
       "1    1623\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6674292-e5da-4732-a6a9-72eaddd10ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced.learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\desktop\\sentiment-analysis-machine-learning-project\\env\\lib\\site-packages (from imbalanced.learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced.learn\n",
      "Successfully installed imbalanced.learn-0.12.4\n"
     ]
    }
   ],
   "source": [
    "# Handle Imbalance Dataset\n",
    "\n",
    "!pip install imbalanced.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0472884-0216-4a70-afb0-62cb6ac5f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9426, 1145) (9426,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "vectorized_x_train_smote, y_train_smote = smote.fit_resample(vectorized_x_train, y_train)\n",
    "print(vectorized_x_train_smote.shape, y_train_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f27c5e96-cbfc-49e7-bce6-83a847ca3c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    4713\n",
       "0    4713\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180fe7f-fb11-49af-911c-05cdcb16b72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
